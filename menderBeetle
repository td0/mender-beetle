#!/usr/bin/env node
const fs = require('fs')
const path = require('path')
const util = require('util')
const fetch = require('node-fetch')
const chalk = require('chalk')
const prompts = require('prompts')
const Log = {
  d: console.debug,
  e: console.error,
  l: console.log,
  i: console.info,
  w: console.warn,
}

// configurable sources
const WORKERS = []
const JSON_FILES = [{title: 'Load from URL...', value: '/URL/'}]

const terminate = (code = 99) => {
  const error = code < 20 ? 'Setup failed' : 'Runtime error'
  Log.e(chalk`\n{red.bold ${error}, shutting down} {yellow (${code})}`)
  process.exit(0)
}

const isCsv = (fileName) => /^.*\.csv$/.test(fileName)

const fileFinder = async (dirName, isSourceFile) => {
  const pattern = isSourceFile 
    ? /([a-zA-Z0-9\s_\\.\-\(\):])+(\.json|\.csv)$/i 
    : /([a-zA-Z0-9\s_\\.\-\(\):])+(\.js)$/i
  const directoryPath = path.join(__dirname, dirName)
  
  let result = false
  await util.promisify(fs.readdir)(directoryPath)
    .then(files => {
      files = files.filter(file => file.match(pattern))
      if (files.length === 0) {
        if (isSourceFile) result = []
        else return Promise.reject('No object worker available!')
      } else {
        const list = []
        files.forEach(file => {
          const title = file
          const value = file
          list.push({title, value})
        })
        result = list.length > 0 ? list : false
      }
    })
    .catch(err => {
      Log.e(chalk`\n{red.bold Error!!}\n{yellow ${err}}\n`)
    })
  return result
}

const parseCsv = (filePath, EXIT_CODE) => {
  try {
    const csv = require('csv-string')
    const fileData = fs.readFileSync(`./sourceData/${filePath}`, 'utf-8')
    return {
      delimiter: csv.detect(fileData),
      object: csv.parse(fileData, { output: 'objects' })
    }
  } catch (err)  {
    Log.e(chalk`{red parseCsv error}`)
    Log.e(err)
    terminate(EXIT_CODE)
  }
}

const fetchJSON = async (jsonUrl) => {
  let json
  await fetch(jsonUrl, { method: "Get" })
    .then(res => res.text())
    .then(res => {
      let len = res.length
      let warningFlag = false
      let unicodeIndices = []
      for (let i = 0; i < len; ++i) {
        if (res.charCodeAt(i) > 127) {
          --len
          res = res.substr(0,i) + res.substr(i+1)
          warningFlag = !warningFlag ? true : warningFlag
          unicodeIndices.push(i)
        }
      }
      if (!warningFlag) {
        Log.e(chalk`\n{red.bold WARNING!}\n{yellow unicode char found at the following indices:}`)
        Log.i(unicodeIndices, '\n')
      }
      json = res
    })
    .catch(err => {
      Log.e(chalk`\n{red.bold JSON Fetch Error}\n{yellow ${err}}`)
    })
  return JSON.parse(json)
}

const generateFileName = (str) => {
  if (str.indexOf('http') > -1) {
    const splitted = str.split('/')
    const len = splitted.length
    const name = splitted[len-1] || 'output.json'
    return name.match(/([a-zA-Z0-9\s_\\.\-\(\):])+(.json)$/i) ? name : name+'.json'
  } else {
    return `${str.replace('/', '')}`
  }
}

const generateFile = async (fileName, data, opt = {}) => {
  const {
    minify = true,
    isCsv = false,
    length = 0
  } = opt
  const str = isCsv ? data : minify ? JSON.stringify(data) : JSON.stringify(data, null, 2)
  const outputDir = './output/'
  const ext = isCsv ? '.csv' : '.json'
  fileName = fileName.replace(/\.(csv|json)$/, ext)
  if (!fs.existsSync(outputDir)) fs.mkdirSync(outputDir);
  try {
    await fs.promises.writeFile(`${outputDir}${fileName}`, str, 'utf8')
    Log.i(chalk`{yellow ${length}} {green entries have been successfully written!\nFile location:} {yellow.underline "output/${fileName}"}\n`)
  } catch(err) {
    Log.e(chalk`\n{red.bold Error while writing the file!}\n{yellow ${err}}`);
  }
}

const setupPrompt = async () => {
  const validateUrl = val => /^(?:(?:(?:https?|ftp):)?\/\/)(?:\S+(?::\S*)?@)?(?:(?!(?:10|127)(?:\.\d{1,3}){3})(?!(?:169\.254|192\.168)(?:\.\d{1,3}){2})(?!172\.(?:1[6-9]|2\d|3[0-1])(?:\.\d{1,3}){2})(?:[1-9]\d?|1\d\d|2[01]\d|22[0-3])(?:\.(?:1?\d{1,2}|2[0-4]\d|25[0-5])){2}(?:\.(?:[1-9]\d?|1\d\d|2[0-4]\d|25[0-4]))|(?:(?:[a-z\u00a1-\uffff0-9]-*)*[a-z\u00a1-\uffff0-9]+)(?:\.(?:[a-z\u00a1-\uffff0-9]-*)*[a-z\u00a1-\uffff0-9]+)*(?:\.(?:[a-z\u00a1-\uffff]{2,})))(?::\d{2,5})?(?:[/?#]\S*)?$/i.test(val)
  try{ 
    const options = await prompts([{
      type: 'autocomplete',
      name: 'fileSrc',
      message: 'Enter file source:',
      choices: JSON_FILES,
    }, {
      type: prev => prev === '/URL/' ? 'text' : false,
      name: 'fileUrl',
      message: 'Enter JSON URL:',
      validate: val => val && validateUrl(val) ? true : 'Please input the URL properly',
    }, {
      type: 'select',
      name: 'objWorker',
      message: 'Pick an Object Worker:',
      instructions: false,
      choices: WORKERS,
    }, {
      type: (_, values) => !isCsv(values.fileSrc) ? 'confirm' : null,
      name: 'minifyOutput',
      message: 'Minify JSON output?',
      initial: true,
    }, {
      type: (_, values) => isCsv(values.fileSrc) ? 'confirm' : null,
      name: 'jsonOutput',
      message: 'Convert the result to JSON?',
      initial: false,
    }])
    return options.fileSrc && options.objWorker ? options : false
  } catch (err) {
    Log.e(chalk`{red Prompter failed: ${err}}`)
    return false
  }
}

const postProcessingPrompt = async () => {
  try{ 
    return await prompts([{
      type: 'autocomplete',
      name: 'splitType',
      message: 'Split CSV file?',
      choices: [
        { title: 'no', value: 'no' },
        { title: 'based on file size', value: 'size' },
        { title: 'based on file count', value: 'fileCount' },
        { title: 'based on item count per file', value: 'itemCount' }
      ],
    }, {
      type: (_, values) => values.splitType === 'size' ? 'number': null,
      name: 'splitSize',
      message: 'How much the maximum file size? (in KB)',
      initial: 20,
      min: 20
    }, {
      type: (_, values) => values.splitType === 'fileCount' ? 'number' : null,
      name: 'splitSize',
      message: 'How much files do you want to split into?',
      initial: 5,
      min: 2,
      max: 20
    },  {
      type: (_, values) => values.splitType === 'itemCount' ? 'number' : null,
      name: 'splitSize',
      message: 'How much the max item per file?',
      initial: 5,
      min: 5
    }])
  } catch (err) {
    Log.e(chalk`{rednPrompter failed: ${err}}`)
    return false
  }
}

const postProcessing = async (file, opt = {}) => {
  const { isCsv, delimiter } = opt
  if (!isCsv) return
  const OPTIONS = await postProcessingPrompt()
  if (OPTIONS.splitType === 'no') return
  Log.i(chalk`{yellow Splitting files ...}`)
  const filePath = `./output/${file}`
  const splitter = require('./splitter')
  if (OPTIONS.splitType === 'size') {
    splitter(filePath, { sizeLimit: OPTIONS.splitSize, delimiter })
  }
}

(async function () {
  let EXIT_CODE = 0
  try {
    ++EXIT_CODE
    JSON_FILES.push(...await fileFinder('sourceData', true))

    ++EXIT_CODE
    WORKERS.push(...await fileFinder('objectWorkers'))

    ++EXIT_CODE
    const OPTIONS = await setupPrompt()
    !OPTIONS && terminate(EXIT_CODE)
    const IS_CSV = isCsv(OPTIONS?.fileSrc)

    EXIT_CODE = 21
    let sourceData
    let csvDelimiter = ','
    ++EXIT_CODE
    if (IS_CSV) {
      Log.i(chalk`{yellow Converting .csv to .json}`)
      const { delimiter, object } = parseCsv(OPTIONS.fileSrc, EXIT_CODE)
      csvDelimiter = delimiter
      sourceData = object
    } else {
      ++EXIT_CODE
      sourceData = OPTIONS.fileUrl 
        ? await fetchJSON(OPTIONS.fileUrl) 
        : require(`./sourceData/${OPTIONS.fileSrc}`)
    }
    !sourceData && terminate(EXIT_CODE)

    ++EXIT_CODE
    const objWorker = require(`./objectWorkers/${OPTIONS.objWorker}`)
    ++EXIT_CODE
    Log.i(chalk`{blue \n>> [START] Worker}`)
    let result = objWorker(sourceData)
    Log.i(chalk`{blue << [END] Worker\n}`)
    ++EXIT_CODE
    
    const itemLength = result.length
    const outputFile = `${generateFileName(OPTIONS.fileUrl || OPTIONS.fileSrc)}`

    ++EXIT_CODE
    if (IS_CSV && !OPTIONS.jsonOutput) {
      Log.i(chalk`{yellow Reverting .json to .csv}`)
      const Parser = require('@json2csv/plainjs').Parser
      const parser = new Parser({
        delimiter: csvDelimiter,
        eol: '\r\n',
        includeEmptyRows: true
      })
      result = parser.parse(result)
    }

    await generateFile(outputFile, result, {
      minify: OPTIONS.minifyOutput,
      isCsv: IS_CSV && !OPTIONS.jsonOutput,
      length: itemLength
    })

    postProcessing(outputFile, {
      minify: OPTIONS.minifyOutput,
      isCsv: IS_CSV && !OPTIONS.jsonOutput,
      delimiter: csvDelimiter
    })
  } catch (err) {
    Log.e(chalk`{red ${err}}`)
    terminate(EXIT_CODE)
  }
})()